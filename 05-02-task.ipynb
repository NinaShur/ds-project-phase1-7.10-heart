{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0225c34d-d153-4b63-99f3-20f3de5bfba9",
   "metadata": {},
   "source": [
    "## Неделя 2. Вторник \n",
    "### Обучение с учителем"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75159857-a2de-4df2-8fd1-646e476e3766",
   "metadata": {},
   "source": [
    "### Применение ансаблей моделей для задач классификации и регрессии"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4f30309-f0f0-4307-9f03-a777c21d25e5",
   "metadata": {},
   "source": [
    "1. Загружаем предобработанный датасет (либо загружаем и очищаем, если не осталось сохраненной версии)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c097c37-154e-46c4-ad7c-7234b6693d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler, MinMaxScaler, OrdinalEncoder, TargetEncoder\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# for model learning\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "\n",
    "#models\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# tunning hyperparamters model\n",
    "import optuna\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import joblib\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d17f7f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем предобработанные датасеты\n",
    "df_train = pd.read_csv('X_train_imputed.csv')\n",
    "df_valid = pd.read_csv('X_valid_imputed.csv')\n",
    "\n",
    "# Отделяем признаки и целевую переменную\n",
    "X_train = df_train.drop('HeartDisease', axis=1)\n",
    "y_train = df_train['HeartDisease']\n",
    "\n",
    "X_valid = df_valid.drop('HeartDisease', axis=1)\n",
    "y_valid = df_valid['HeartDisease']\n",
    "\n",
    "\n",
    "# Кодируем пол как числовой признак (например, M=0, F=1)\n",
    "X_train['Sex'] = X_train['Sex'].map({'M': 0, 'F': 1})\n",
    "X_valid['Sex'] = X_valid['Sex'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Обновляем списки признаков: теперь Sex — числовой\n",
    "num_features = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak', 'Sex']\n",
    "# Категориальные признаки\n",
    "cat_features = ['ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "\n",
    "# Пайплайны\n",
    "num_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_onehot_pipeline = Pipeline([\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Label Encoding категорий вручную\n",
    "label_encoders = {}\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    X_valid[col] = le.transform(X_valid[col])\n",
    "    label_encoders[col] = le  # можно сохранить, если понадобится\n",
    "\n",
    "# Теперь все признаки числовые\n",
    "num_features = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak', 'Sex'] + cat_features\n",
    "\n",
    "# Пайплайн — масштабируем только числовые признаки (без категорий, т.к. это метки)\n",
    "# Можно масштабировать все, но для категорий — не обязательно и даже вредно.\n",
    "# Поэтому масштабируем только числовые (без категорий)\n",
    "num_only_features = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak', 'Sex']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_only_features)\n",
    "], remainder='passthrough')  # остальные признаки (категории) без изменений"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1092ba61-e544-4f66-9050-8ceeb91905d5",
   "metadata": {},
   "source": [
    "2. К прежним датасетам применяем ансамбли моделей: \n",
    "    - `RandomForest`\n",
    "    - `Voting`\n",
    "    - `Catboost`([https://catboost.ai/en/docs/concepts/python-installation](https://catboost.ai/en/docs/concepts/python-installation))\n",
    "    - `LightGBM`([https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html](https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html))\n",
    "    - `XGBoost` ([https://xgboost.readthedocs.io/en/latest/install.html](https://xgboost.readthedocs.io/en/latest/install.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296a7b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.8641304347826086\n"
     ]
    }
   ],
   "source": [
    "# Модели\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "cat = CatBoostClassifier(random_state=42, verbose=0)\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "xgb = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "# Ансамбль\n",
    "voting_clf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('voting', VotingClassifier(estimators=[\n",
    "        ('rf', rf),\n",
    "        ('cat', cat),\n",
    "        ('lgbm', lgbm),\n",
    "        ('xgb', xgb)\n",
    "    ], voting='soft'))\n",
    "])\n",
    "\n",
    "# Обучение\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Оценка\n",
    "print(\"Voting Classifier Accuracy:\", voting_clf.score(X_valid, y_valid))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f015ae7e-40bc-473c-a74b-402fce2445b5",
   "metadata": {},
   "source": [
    "# ❓\n",
    "Какие значения по умолчанию заданы в случайном лесе для числа деревьев и их глубины?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b80bc438-483f-4f36-85f5-5088b338a76c",
   "metadata": {},
   "source": [
    "В RandomForestClassifier из scikit-learn значения по умолчанию следующие:\n",
    "\n",
    "n_estimators — количество деревьев\n",
    "По умолчанию: 100\n",
    "То есть лес состоит из 100 деревьев, если не указали другое\n",
    "\n",
    "max_depth — максимальная глубина каждого дерева\n",
    "По умолчанию: None\n",
    "Это значит, что дерево будет расти до тех пор, пока: не достигнет чистых листьев (один класс) или пока не закончится минимум по выборке (например, min_samples_split=2).\n",
    "Такая глубина может привести к переобучению, особенно на шумных или небольших датасетах"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "920071b4-09b5-4672-8d7e-eb77fd09cf45",
   "metadata": {},
   "source": [
    "3. Прогоните модели через `optuna`, определяем лучшие параметры и сохраняем результат в словарь вида:\n",
    "    ```python\n",
    "    results = {'model_name' : best_result}\n",
    "    ```\n",
    "\n",
    "Типичные параметры для оптимизации градиентного бустинга: \n",
    "* число итераций алгоритма\n",
    "* глубина деревьев\n",
    "* скорость обучения (`learning_rate`). \n",
    "Чтобы попробовать оптимизировать модели, стоит обратиться к документации: разные реализации будут предлагать разные варианты параметров. \n",
    "\n",
    "   > Для классификации используем метрику `accuracy_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f0b1c5f-b525-49c4-b4bf-f08e76c215da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 20:22:54,775] A new study created in memory with name: no-name-63dc9f75-9d4a-4bda-ba50-04c15a1d5f40\n",
      "[I 2025-10-07 20:22:54,857] Trial 0 finished with value: 0.9021739130434783 and parameters: {'iterations': 178, 'depth': 4, 'learning_rate': 0.05891231841043741}. Best is trial 0 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:22:54,926] Trial 1 finished with value: 0.875 and parameters: {'iterations': 165, 'depth': 4, 'learning_rate': 0.14421686626690472}. Best is trial 0 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:22:55,749] Trial 2 finished with value: 0.8858695652173914 and parameters: {'iterations': 169, 'depth': 10, 'learning_rate': 0.17024536750930047}. Best is trial 0 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:22:55,960] Trial 3 finished with value: 0.8641304347826086 and parameters: {'iterations': 325, 'depth': 3, 'learning_rate': 0.14485598831021815}. Best is trial 0 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:22:58,224] Trial 4 finished with value: 0.875 and parameters: {'iterations': 450, 'depth': 10, 'learning_rate': 0.05244217496588661}. Best is trial 0 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:22:58,301] Trial 5 finished with value: 0.8967391304347826 and parameters: {'iterations': 138, 'depth': 5, 'learning_rate': 0.2260174356111028}. Best is trial 0 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:22:59,036] Trial 6 finished with value: 0.8858695652173914 and parameters: {'iterations': 172, 'depth': 10, 'learning_rate': 0.08370785796825156}. Best is trial 0 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:22:59,243] Trial 7 finished with value: 0.8641304347826086 and parameters: {'iterations': 206, 'depth': 6, 'learning_rate': 0.14686917833142074}. Best is trial 0 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:22:59,585] Trial 8 finished with value: 0.8641304347826086 and parameters: {'iterations': 433, 'depth': 4, 'learning_rate': 0.0925617772849625}. Best is trial 0 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:00,433] Trial 9 finished with value: 0.8858695652173914 and parameters: {'iterations': 406, 'depth': 8, 'learning_rate': 0.15169536116550095}. Best is trial 0 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:01,008] Trial 10 finished with value: 0.8695652173913043 and parameters: {'iterations': 268, 'depth': 8, 'learning_rate': 0.29618512804120056}. Best is trial 0 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:01,123] Trial 11 finished with value: 0.8858695652173914 and parameters: {'iterations': 114, 'depth': 5, 'learning_rate': 0.2523897950351497}. Best is trial 0 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:01,238] Trial 12 finished with value: 0.8695652173913043 and parameters: {'iterations': 110, 'depth': 6, 'learning_rate': 0.21699736478228684}. Best is trial 0 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:01,394] Trial 13 finished with value: 0.907608695652174 and parameters: {'iterations': 238, 'depth': 3, 'learning_rate': 0.026024565188143937}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:01,623] Trial 14 finished with value: 0.8913043478260869 and parameters: {'iterations': 249, 'depth': 3, 'learning_rate': 0.012584738407773965}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:01,956] Trial 15 finished with value: 0.8967391304347826 and parameters: {'iterations': 320, 'depth': 3, 'learning_rate': 0.020830889075710714}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:02,202] Trial 16 finished with value: 0.8804347826086957 and parameters: {'iterations': 230, 'depth': 4, 'learning_rate': 0.08434509139468038}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:02,608] Trial 17 finished with value: 0.8913043478260869 and parameters: {'iterations': 387, 'depth': 5, 'learning_rate': 0.051331349809589685}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:03,075] Trial 18 finished with value: 0.8858695652173914 and parameters: {'iterations': 289, 'depth': 7, 'learning_rate': 0.11065406410185999}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:03,290] Trial 19 finished with value: 0.8967391304347826 and parameters: {'iterations': 208, 'depth': 4, 'learning_rate': 0.04100346773068552}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:03,632] Trial 20 finished with value: 0.8641304347826086 and parameters: {'iterations': 347, 'depth': 3, 'learning_rate': 0.11344425502772736}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:03,740] Trial 21 finished with value: 0.8913043478260869 and parameters: {'iterations': 141, 'depth': 5, 'learning_rate': 0.20237036953171017}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:03,996] Trial 22 finished with value: 0.8804347826086957 and parameters: {'iterations': 213, 'depth': 5, 'learning_rate': 0.2799534001506714}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:04,070] Trial 23 finished with value: 0.8804347826086957 and parameters: {'iterations': 143, 'depth': 4, 'learning_rate': 0.19942769502102842}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:04,687] Trial 24 finished with value: 0.8967391304347826 and parameters: {'iterations': 485, 'depth': 6, 'learning_rate': 0.24295752919471794}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:04,753] Trial 25 finished with value: 0.9021739130434783 and parameters: {'iterations': 185, 'depth': 3, 'learning_rate': 0.03645682707196275}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:04,941] Trial 26 finished with value: 0.8967391304347826 and parameters: {'iterations': 273, 'depth': 3, 'learning_rate': 0.03393488177009073}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:05,011] Trial 27 finished with value: 0.907608695652174 and parameters: {'iterations': 186, 'depth': 3, 'learning_rate': 0.06785418585998021}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:05,245] Trial 28 finished with value: 0.8858695652173914 and parameters: {'iterations': 234, 'depth': 4, 'learning_rate': 0.06363905358035833}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:05,366] Trial 29 finished with value: 0.8858695652173914 and parameters: {'iterations': 192, 'depth': 4, 'learning_rate': 0.11863649043633302}. Best is trial 13 with value: 0.907608695652174.\n",
      "[I 2025-10-07 20:23:05,367] A new study created in memory with name: no-name-e36479aa-c9a5-48c1-a348-99a9f95333e7\n",
      "[I 2025-10-07 20:23:05,531] Trial 0 finished with value: 0.842391304347826 and parameters: {'n_estimators': 466, 'max_depth': 3, 'learning_rate': 0.14238220691552078}. Best is trial 0 with value: 0.842391304347826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CatBoost Accuracy: 0.907608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 20:23:05,751] Trial 1 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 449, 'max_depth': 15, 'learning_rate': 0.1753906520945527}. Best is trial 1 with value: 0.8695652173913043.\n",
      "[I 2025-10-07 20:23:05,923] Trial 2 finished with value: 0.8804347826086957 and parameters: {'n_estimators': 250, 'max_depth': 15, 'learning_rate': 0.025531370254229482}. Best is trial 2 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 20:23:06,103] Trial 3 finished with value: 0.8804347826086957 and parameters: {'n_estimators': 288, 'max_depth': 15, 'learning_rate': 0.03279855297923204}. Best is trial 2 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 20:23:06,236] Trial 4 finished with value: 0.875 and parameters: {'n_estimators': 323, 'max_depth': 6, 'learning_rate': 0.022476737655956744}. Best is trial 2 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 20:23:06,328] Trial 5 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 129, 'max_depth': 13, 'learning_rate': 0.2887063085930615}. Best is trial 2 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 20:23:06,431] Trial 6 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 180, 'max_depth': 8, 'learning_rate': 0.04149081442599885}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:06,559] Trial 7 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 318, 'max_depth': 6, 'learning_rate': 0.05032225001381179}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:06,659] Trial 8 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 193, 'max_depth': 8, 'learning_rate': 0.22953836210752296}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:06,886] Trial 9 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 400, 'max_depth': 13, 'learning_rate': 0.12276672976243572}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:06,966] Trial 10 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 122, 'max_depth': 10, 'learning_rate': 0.09306307492429129}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:07,095] Trial 11 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 226, 'max_depth': 10, 'learning_rate': 0.07320649310148981}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:07,206] Trial 12 finished with value: 0.8858695652173914 and parameters: {'n_estimators': 208, 'max_depth': 7, 'learning_rate': 0.016457831225058006}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:07,305] Trial 13 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 186, 'max_depth': 7, 'learning_rate': 0.08050661886663532}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:07,340] Trial 14 finished with value: 0.8532608695652174 and parameters: {'n_estimators': 158, 'max_depth': 3, 'learning_rate': 0.18293446788471618}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:07,439] Trial 15 finished with value: 0.875 and parameters: {'n_estimators': 252, 'max_depth': 5, 'learning_rate': 0.01349884258761487}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:07,559] Trial 16 finished with value: 0.8478260869565217 and parameters: {'n_estimators': 205, 'max_depth': 9, 'learning_rate': 0.10820368171202813}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:07,793] Trial 17 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 388, 'max_depth': 11, 'learning_rate': 0.06418311430658644}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:07,855] Trial 18 finished with value: 0.8532608695652174 and parameters: {'n_estimators': 103, 'max_depth': 8, 'learning_rate': 0.22443299945896775}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:07,917] Trial 19 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 160, 'max_depth': 5, 'learning_rate': 0.04790771731081016}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:08,081] Trial 20 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 264, 'max_depth': 11, 'learning_rate': 0.12825292688608725}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:08,214] Trial 21 finished with value: 0.875 and parameters: {'n_estimators': 239, 'max_depth': 8, 'learning_rate': 0.01985981455786002}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:08,389] Trial 22 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 292, 'max_depth': 12, 'learning_rate': 0.046205650807110116}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:08,564] Trial 23 finished with value: 0.8858695652173914 and parameters: {'n_estimators': 361, 'max_depth': 7, 'learning_rate': 0.011232680187919973}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:08,722] Trial 24 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 357, 'max_depth': 7, 'learning_rate': 0.0931233855388591}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:08,848] Trial 25 finished with value: 0.8858695652173914 and parameters: {'n_estimators': 355, 'max_depth': 5, 'learning_rate': 0.012132396984744324}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:09,059] Trial 26 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 431, 'max_depth': 7, 'learning_rate': 0.06023146356704317}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:09,159] Trial 27 finished with value: 0.8804347826086957 and parameters: {'n_estimators': 161, 'max_depth': 9, 'learning_rate': 0.042811796455207086}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:09,278] Trial 28 finished with value: 0.8478260869565217 and parameters: {'n_estimators': 498, 'max_depth': 4, 'learning_rate': 0.0710483898042184}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:09,369] Trial 29 finished with value: 0.8369565217391305 and parameters: {'n_estimators': 211, 'max_depth': 6, 'learning_rate': 0.16753660994544686}. Best is trial 6 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 20:23:09,370] A new study created in memory with name: no-name-d8521dbb-556a-4798-9891-852c3e7cb26e\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LightGBM Accuracy: 0.8913043478260869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 20:23:11,855] Trial 0 finished with value: 0.8532608695652174 and parameters: {'n_estimators': 462, 'max_depth': 7, 'learning_rate': 0.03725598083099277}. Best is trial 0 with value: 0.8532608695652174.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:12,761] Trial 1 finished with value: 0.875 and parameters: {'n_estimators': 260, 'max_depth': 8, 'learning_rate': 0.26545399590083957}. Best is trial 1 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:14,186] Trial 2 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 463, 'max_depth': 5, 'learning_rate': 0.14284131730210292}. Best is trial 1 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:14,826] Trial 3 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 122, 'max_depth': 9, 'learning_rate': 0.21069889229561128}. Best is trial 1 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:16,561] Trial 4 finished with value: 0.8478260869565217 and parameters: {'n_estimators': 385, 'max_depth': 14, 'learning_rate': 0.011582238660297289}. Best is trial 1 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:16,939] Trial 5 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 168, 'max_depth': 3, 'learning_rate': 0.19321111519265508}. Best is trial 1 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:17,841] Trial 6 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 180, 'max_depth': 9, 'learning_rate': 0.2009863661884753}. Best is trial 1 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:17] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:18,547] Trial 7 finished with value: 0.875 and parameters: {'n_estimators': 222, 'max_depth': 5, 'learning_rate': 0.02471902622030932}. Best is trial 1 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:18,892] Trial 8 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 159, 'max_depth': 5, 'learning_rate': 0.20494863640823385}. Best is trial 1 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:20,689] Trial 9 finished with value: 0.8804347826086957 and parameters: {'n_estimators': 358, 'max_depth': 14, 'learning_rate': 0.0933758781122628}. Best is trial 9 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:21,776] Trial 10 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 327, 'max_depth': 15, 'learning_rate': 0.09889738090071028}. Best is trial 9 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:22,994] Trial 11 finished with value: 0.8478260869565217 and parameters: {'n_estimators': 279, 'max_depth': 12, 'learning_rate': 0.2873840337612231}. Best is trial 9 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:23,940] Trial 12 finished with value: 0.8532608695652174 and parameters: {'n_estimators': 357, 'max_depth': 12, 'learning_rate': 0.28423701444213856}. Best is trial 9 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:25,211] Trial 13 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 257, 'max_depth': 12, 'learning_rate': 0.08491824879524026}. Best is trial 9 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:25] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:27,025] Trial 14 finished with value: 0.8532608695652174 and parameters: {'n_estimators': 401, 'max_depth': 8, 'learning_rate': 0.12444285608082153}. Best is trial 9 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:28,200] Trial 15 finished with value: 0.8532608695652174 and parameters: {'n_estimators': 306, 'max_depth': 10, 'learning_rate': 0.2556176897239675}. Best is trial 9 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:29,760] Trial 16 finished with value: 0.8532608695652174 and parameters: {'n_estimators': 232, 'max_depth': 11, 'learning_rate': 0.06053092585207033}. Best is trial 9 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:30,638] Trial 17 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 395, 'max_depth': 7, 'learning_rate': 0.24293079671300355}. Best is trial 9 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:31,608] Trial 18 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 345, 'max_depth': 15, 'learning_rate': 0.16618526734095446}. Best is trial 9 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:32,725] Trial 19 finished with value: 0.875 and parameters: {'n_estimators': 285, 'max_depth': 13, 'learning_rate': 0.09872120695262888}. Best is trial 9 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:34,239] Trial 20 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 434, 'max_depth': 10, 'learning_rate': 0.15960142902811572}. Best is trial 9 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:35,057] Trial 21 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 234, 'max_depth': 5, 'learning_rate': 0.05028464544687252}. Best is trial 9 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:35,428] Trial 22 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 214, 'max_depth': 3, 'learning_rate': 0.01815229080788919}. Best is trial 22 with value: 0.8967391304347826.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:35,882] Trial 23 finished with value: 0.875 and parameters: {'n_estimators': 203, 'max_depth': 3, 'learning_rate': 0.07661006001737793}. Best is trial 22 with value: 0.8967391304347826.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:36,214] Trial 24 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 104, 'max_depth': 7, 'learning_rate': 0.13294173798209338}. Best is trial 22 with value: 0.8967391304347826.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:36,950] Trial 25 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 311, 'max_depth': 4, 'learning_rate': 0.1130007971844357}. Best is trial 22 with value: 0.8967391304347826.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:37,952] Trial 26 finished with value: 0.8532608695652174 and parameters: {'n_estimators': 261, 'max_depth': 6, 'learning_rate': 0.17600345348904356}. Best is trial 22 with value: 0.8967391304347826.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:39,011] Trial 27 finished with value: 0.8478260869565217 and parameters: {'n_estimators': 363, 'max_depth': 8, 'learning_rate': 0.23449221398295317}. Best is trial 22 with value: 0.8967391304347826.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:39,949] Trial 28 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 257, 'max_depth': 14, 'learning_rate': 0.06246385488517994}. Best is trial 22 with value: 0.8967391304347826.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [20:23:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 20:23:40,751] Trial 29 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 204, 'max_depth': 10, 'learning_rate': 0.0371519908043936}. Best is trial 22 with value: 0.8967391304347826.\n",
      "[I 2025-10-07 20:23:40,752] A new study created in memory with name: no-name-f43cce0b-21fb-4af8-aaef-58c9dd28d4f9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Accuracy: 0.8967391304347826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 20:23:41,028] Trial 0 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 171, 'max_depth': 19, 'min_samples_split': 2}. Best is trial 0 with value: 0.8967391304347826.\n",
      "[I 2025-10-07 20:23:41,158] Trial 1 finished with value: 0.8858695652173914 and parameters: {'n_estimators': 90, 'max_depth': 5, 'min_samples_split': 4}. Best is trial 0 with value: 0.8967391304347826.\n",
      "[I 2025-10-07 20:23:41,452] Trial 2 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 222, 'max_depth': 4, 'min_samples_split': 3}. Best is trial 0 with value: 0.8967391304347826.\n",
      "[I 2025-10-07 20:23:41,549] Trial 3 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 75, 'max_depth': 3, 'min_samples_split': 3}. Best is trial 0 with value: 0.8967391304347826.\n",
      "[I 2025-10-07 20:23:41,767] Trial 4 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 137, 'max_depth': 18, 'min_samples_split': 9}. Best is trial 0 with value: 0.8967391304347826.\n",
      "[I 2025-10-07 20:23:42,151] Trial 5 finished with value: 0.9021739130434783 and parameters: {'n_estimators': 239, 'max_depth': 16, 'min_samples_split': 9}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:42,473] Trial 6 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 198, 'max_depth': 18, 'min_samples_split': 3}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:42,773] Trial 7 finished with value: 0.8804347826086957 and parameters: {'n_estimators': 231, 'max_depth': 3, 'min_samples_split': 7}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:42,906] Trial 8 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 81, 'max_depth': 6, 'min_samples_split': 10}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:43,236] Trial 9 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 178, 'max_depth': 11, 'min_samples_split': 10}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:43,709] Trial 10 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 289, 'max_depth': 13, 'min_samples_split': 7}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:44,157] Trial 11 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 281, 'max_depth': 20, 'min_samples_split': 5}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:44,393] Trial 12 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 144, 'max_depth': 14, 'min_samples_split': 8}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:44,773] Trial 13 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 238, 'max_depth': 16, 'min_samples_split': 6}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:45,005] Trial 14 finished with value: 0.8858695652173914 and parameters: {'n_estimators': 139, 'max_depth': 20, 'min_samples_split': 2}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:45,418] Trial 15 finished with value: 0.8858695652173914 and parameters: {'n_estimators': 258, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:45,707] Trial 16 finished with value: 0.9021739130434783 and parameters: {'n_estimators': 182, 'max_depth': 16, 'min_samples_split': 9}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:46,033] Trial 17 finished with value: 0.9021739130434783 and parameters: {'n_estimators': 207, 'max_depth': 16, 'min_samples_split': 9}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:46,434] Trial 18 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 257, 'max_depth': 8, 'min_samples_split': 8}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:46,617] Trial 19 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 111, 'max_depth': 15, 'min_samples_split': 9}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:46,906] Trial 20 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 184, 'max_depth': 13, 'min_samples_split': 8}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:47,241] Trial 21 finished with value: 0.9021739130434783 and parameters: {'n_estimators': 212, 'max_depth': 16, 'min_samples_split': 9}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:47,572] Trial 22 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 204, 'max_depth': 17, 'min_samples_split': 10}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:47,977] Trial 23 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 258, 'max_depth': 14, 'min_samples_split': 7}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:48,258] Trial 24 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 179, 'max_depth': 16, 'min_samples_split': 9}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:48,513] Trial 25 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 160, 'max_depth': 12, 'min_samples_split': 8}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:48,884] Trial 26 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 240, 'max_depth': 9, 'min_samples_split': 10}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:48,971] Trial 27 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 50, 'max_depth': 18, 'min_samples_split': 6}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:49,285] Trial 28 finished with value: 0.9021739130434783 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 9}. Best is trial 5 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 20:23:49,555] Trial 29 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 167, 'max_depth': 19, 'min_samples_split': 8}. Best is trial 5 with value: 0.9021739130434783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Accuracy: 0.9021739130434783\n",
      "Все результаты: {'CatBoost': 0.907608695652174, 'LightGBM': 0.8913043478260869, 'XGBoost': 0.8967391304347826, 'RandomForest': 0.9021739130434783}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "# Оптимизация для CatBoost\n",
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 500),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return accuracy_score(y_valid, preds)\n",
    "\n",
    "study_cat = optuna.create_study(direction='maximize')\n",
    "study_cat.optimize(objective_catboost, n_trials=30)\n",
    "results['CatBoost'] = study_cat.best_trial.value\n",
    "print(\"Best CatBoost Accuracy:\", study_cat.best_trial.value)\n",
    "\n",
    "# Оптимизация для LightGBM\n",
    "def objective_lgbm(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'random_state': 42,\n",
    "        'verbosity': -1,\n",
    "        'objective': 'binary'\n",
    "    }\n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return accuracy_score(y_valid, preds)\n",
    "\n",
    "study_lgbm = optuna.create_study(direction='maximize')\n",
    "study_lgbm.optimize(objective_lgbm, n_trials=30)\n",
    "results['LightGBM'] = study_lgbm.best_trial.value\n",
    "print(\"Best LightGBM Accuracy:\", study_lgbm.best_trial.value)\n",
    "\n",
    "# Оптимизация для XGBoost\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'random_state': 42,\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return accuracy_score(y_valid, preds)\n",
    "\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=30)\n",
    "results['XGBoost'] = study_xgb.best_trial.value\n",
    "print(\"Best XGBoost Accuracy:\", study_xgb.best_trial.value)\n",
    "\n",
    "# Оптимизация для RandomForest (чтобы было)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return accuracy_score(y_valid, preds)\n",
    "\n",
    "study_rf = optuna.create_study(direction='maximize')\n",
    "study_rf.optimize(objective_rf, n_trials=30)\n",
    "results['RandomForest'] = study_rf.best_trial.value\n",
    "print(\"Best RandomForest Accuracy:\", study_rf.best_trial.value)\n",
    "\n",
    "print(\"Все результаты:\", results)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbb5cfb9-033f-4318-8280-199cdeb6c239",
   "metadata": {},
   "source": [
    "4. Превращаем словарь в `DataFrame` и сравниваем полученные результаты. Строим `bar_plot` для визуализации метрики качества. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a16845f8-619a-4111-b4b3-c2e8abefdc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = {'CatBoost': 0.9130434782608695, \n",
    "           'LightGBM': 0.8913043478260869, \n",
    "           'XGBoost': 0.8804347826086957, \n",
    "           'RandomForest': 0.9021739130434783}\n",
    "\n",
    "df_results = pd.DataFrame(list(results.items()), columns=['Model', 'Accuracy'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(df_results['Model'], df_results['Accuracy'], color='skyblue')\n",
    "plt.title('Сравнение Accuracy моделей')\n",
    "plt.xlabel('Модель')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(df_results['Accuracy']):\n",
    "    plt.text(i, v + 0.01, f\"{v:.3f}\", ha='center', fontsize=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Выберете лучшую модель и попробуйте задеплоить ее в Streamlit.\n",
    "\n",
    "* Создайте просто интерфейс для пользователя, куда бы он мог ввести необходимые данные, а вы бы ему вернули предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1dfc62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c8928ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoders.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import streamlit as st\n",
    "\n",
    "catboost_model = CatBoostClassifier(random_seed=42, verbose=0)\n",
    "catboost_model.fit(X_train, y_train)\n",
    "joblib.dump(catboost_model, 'catboost_model.pkl')\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
    "joblib.dump(label_encoders, 'label_encoders.pkl')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phase1-29.09",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
