{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0225c34d-d153-4b63-99f3-20f3de5bfba9",
   "metadata": {},
   "source": [
    "## Неделя 2. Вторник \n",
    "### Обучение с учителем"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75159857-a2de-4df2-8fd1-646e476e3766",
   "metadata": {},
   "source": [
    "### Применение ансаблей моделей для задач классификации и регрессии"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4f30309-f0f0-4307-9f03-a777c21d25e5",
   "metadata": {},
   "source": [
    "1. Загружаем предобработанный датасет (либо загружаем и очищаем, если не осталось сохраненной версии)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9c097c37-154e-46c4-ad7c-7234b6693d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Важная настройка для корректной настройки pipeline!\n",
    "import sklearn\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler, MinMaxScaler, OrdinalEncoder, TargetEncoder\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# for model learning\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "\n",
    "#models\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# tunning hyperparamters model\n",
    "import optuna\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d17f7f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем предобработанные датасеты\n",
    "df_train = pd.read_csv('aux/X_train_imputed.csv')\n",
    "df_valid = pd.read_csv('aux/X_valid_imputed.csv')\n",
    "\n",
    "# Отделяем признаки и целевую переменную\n",
    "X_train = df_train.drop('HeartDisease', axis=1)\n",
    "y_train = df_train['HeartDisease']\n",
    "\n",
    "X_valid = df_valid.drop('HeartDisease', axis=1)\n",
    "y_valid = df_valid['HeartDisease']\n",
    "\n",
    "\n",
    "# Кодируем пол как числовой признак (например, M=0, F=1)\n",
    "X_train['Sex'] = X_train['Sex'].map({'M': 0, 'F': 1})\n",
    "X_valid['Sex'] = X_valid['Sex'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Обновляем списки признаков: теперь Sex — числовой\n",
    "num_features = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak', 'Sex']\n",
    "# Категориальные признаки\n",
    "cat_features = ['ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "\n",
    "# Пайплайны\n",
    "num_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_onehot_pipeline = Pipeline([\n",
    "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Label Encoding категорий вручную\n",
    "label_encoders = {}\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    X_valid[col] = le.transform(X_valid[col])\n",
    "    label_encoders[col] = le  # можно сохранить, если понадобится\n",
    "\n",
    "# Теперь все признаки числовые\n",
    "num_features = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak', 'Sex'] + cat_features\n",
    "\n",
    "# Пайплайн — масштабируем только числовые признаки (без категорий, т.к. это метки)\n",
    "# Можно масштабировать все, но для категорий — не обязательно и даже вредно.\n",
    "# Поэтому масштабируем только числовые (без категорий)\n",
    "num_only_features = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak', 'Sex']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_only_features)\n",
    "], remainder='passthrough')  # остальные признаки (категории) без изменений"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1092ba61-e544-4f66-9050-8ceeb91905d5",
   "metadata": {},
   "source": [
    "2. К прежним датасетам применяем ансамбли моделей: \n",
    "    - `RandomForest`\n",
    "    - `Voting`\n",
    "    - `Catboost`([https://catboost.ai/en/docs/concepts/python-installation](https://catboost.ai/en/docs/concepts/python-installation))\n",
    "    - `LightGBM`([https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html](https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html))\n",
    "    - `XGBoost` ([https://xgboost.readthedocs.io/en/latest/install.html](https://xgboost.readthedocs.io/en/latest/install.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296a7b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 406, number of negative: 328\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 377\n",
      "[LightGBM] [Info] Number of data points in the train set: 734, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.553134 -> initscore=0.213340\n",
      "[LightGBM] [Info] Start training from score 0.213340\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Voting Classifier Accuracy: 0.8641304347826086\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Модели\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "cat = CatBoostClassifier(random_state=42, verbose=0)\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "xgb = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "# Ансамбль\n",
    "voting_clf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('voting', VotingClassifier(estimators=[\n",
    "        ('rf', rf),\n",
    "        ('cat', cat),\n",
    "        ('lgbm', lgbm),\n",
    "        ('xgb', xgb)\n",
    "    ], voting='soft'))\n",
    "])\n",
    "\n",
    "# Обучение\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Оценка\n",
    "print(\"Voting Classifier Accuracy:\", voting_clf.score(X_valid, y_valid))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f015ae7e-40bc-473c-a74b-402fce2445b5",
   "metadata": {},
   "source": [
    "# ❓\n",
    "Какие значения по умолчанию заданы в случайном лесе для числа деревьев и их глубины?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b80bc438-483f-4f36-85f5-5088b338a76c",
   "metadata": {},
   "source": [
    "В RandomForestClassifier из scikit-learn значения по умолчанию следующие:\n",
    "\n",
    "n_estimators — количество деревьев\n",
    "По умолчанию: 100\n",
    "То есть лес состоит из 100 деревьев, если не указали другое\n",
    "\n",
    "max_depth — максимальная глубина каждого дерева\n",
    "По умолчанию: None\n",
    "Это значит, что дерево будет расти до тех пор, пока: не достигнет чистых листьев (один класс) или пока не закончится минимум по выборке (например, min_samples_split=2).\n",
    "Такая глубина может привести к переобучению, особенно на шумных или небольших датасетах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c990dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "920071b4-09b5-4672-8d7e-eb77fd09cf45",
   "metadata": {},
   "source": [
    "3. Прогоните модели через `optuna`, определяем лучшие параметры и сохраняем результат в словарь вида:\n",
    "    ```python\n",
    "    results = {'model_name' : best_result}\n",
    "    ```\n",
    "\n",
    "Типичные параметры для оптимизации градиентного бустинга: \n",
    "* число итераций алгоритма\n",
    "* глубина деревьев\n",
    "* скорость обучения (`learning_rate`). \n",
    "Чтобы попробовать оптимизировать модели, стоит обратиться к документации: разные реализации будут предлагать разные варианты параметров. \n",
    "\n",
    "   > Для классификации используем метрику `accuracy_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2f0b1c5f-b525-49c4-b4bf-f08e76c215da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 16:43:15,481] A new study created in memory with name: no-name-716ce7d3-08c8-473d-9c7a-8b5ed32f404c\n",
      "[I 2025-10-07 16:43:17,073] Trial 0 finished with value: 0.8695652173913043 and parameters: {'iterations': 320, 'depth': 10, 'learning_rate': 0.05390813324164266}. Best is trial 0 with value: 0.8695652173913043.\n",
      "[I 2025-10-07 16:43:17,277] Trial 1 finished with value: 0.875 and parameters: {'iterations': 282, 'depth': 4, 'learning_rate': 0.1689106652605104}. Best is trial 1 with value: 0.875.\n",
      "[I 2025-10-07 16:43:17,570] Trial 2 finished with value: 0.907608695652174 and parameters: {'iterations': 178, 'depth': 8, 'learning_rate': 0.20362023935166823}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:17,718] Trial 3 finished with value: 0.8695652173913043 and parameters: {'iterations': 212, 'depth': 3, 'learning_rate': 0.08683161865505164}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:17,825] Trial 4 finished with value: 0.8804347826086957 and parameters: {'iterations': 134, 'depth': 6, 'learning_rate': 0.19139276747597625}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:18,696] Trial 5 finished with value: 0.8967391304347826 and parameters: {'iterations': 434, 'depth': 8, 'learning_rate': 0.21383083709385234}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:19,090] Trial 6 finished with value: 0.907608695652174 and parameters: {'iterations': 406, 'depth': 6, 'learning_rate': 0.010500376458382275}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:19,381] Trial 7 finished with value: 0.8695652173913043 and parameters: {'iterations': 409, 'depth': 4, 'learning_rate': 0.24386508494132308}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:19,468] Trial 8 finished with value: 0.907608695652174 and parameters: {'iterations': 171, 'depth': 5, 'learning_rate': 0.1144993940577141}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:19,547] Trial 9 finished with value: 0.8858695652173914 and parameters: {'iterations': 102, 'depth': 6, 'learning_rate': 0.19495011125184725}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:20,311] Trial 10 finished with value: 0.8695652173913043 and parameters: {'iterations': 257, 'depth': 9, 'learning_rate': 0.28958386344592}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:21,017] Trial 11 finished with value: 0.9021739130434783 and parameters: {'iterations': 377, 'depth': 8, 'learning_rate': 0.028950560249662735}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:21,753] Trial 12 finished with value: 0.8695652173913043 and parameters: {'iterations': 495, 'depth': 7, 'learning_rate': 0.12683095749747217}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:22,243] Trial 13 finished with value: 0.875 and parameters: {'iterations': 343, 'depth': 7, 'learning_rate': 0.2535614859157006}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:22,700] Trial 14 finished with value: 0.8804347826086957 and parameters: {'iterations': 223, 'depth': 8, 'learning_rate': 0.14058887210989088}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:24,873] Trial 15 finished with value: 0.8913043478260869 and parameters: {'iterations': 466, 'depth': 10, 'learning_rate': 0.018241429537949855}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:25,192] Trial 16 finished with value: 0.875 and parameters: {'iterations': 361, 'depth': 5, 'learning_rate': 0.0820317360524887}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:25,707] Trial 17 finished with value: 0.8858695652173914 and parameters: {'iterations': 190, 'depth': 9, 'learning_rate': 0.23095039515936544}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:26,104] Trial 18 finished with value: 0.8804347826086957 and parameters: {'iterations': 283, 'depth': 7, 'learning_rate': 0.2950416485081808}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:26,455] Trial 19 finished with value: 0.8858695652173914 and parameters: {'iterations': 393, 'depth': 5, 'learning_rate': 0.16520093313303935}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:27,214] Trial 20 finished with value: 0.8695652173913043 and parameters: {'iterations': 248, 'depth': 9, 'learning_rate': 0.09076694084312163}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:27,361] Trial 21 finished with value: 0.8913043478260869 and parameters: {'iterations': 160, 'depth': 6, 'learning_rate': 0.11458804832126818}. Best is trial 2 with value: 0.907608695652174.\n",
      "[I 2025-10-07 16:43:27,555] Trial 22 finished with value: 0.9130434782608695 and parameters: {'iterations': 178, 'depth': 5, 'learning_rate': 0.05092135927066989}. Best is trial 22 with value: 0.9130434782608695.\n",
      "[I 2025-10-07 16:43:27,609] Trial 23 finished with value: 0.8804347826086957 and parameters: {'iterations': 102, 'depth': 4, 'learning_rate': 0.03867056567296338}. Best is trial 22 with value: 0.9130434782608695.\n",
      "[I 2025-10-07 16:43:28,037] Trial 24 finished with value: 0.9130434782608695 and parameters: {'iterations': 143, 'depth': 5, 'learning_rate': 0.05872030942285122}. Best is trial 22 with value: 0.9130434782608695.\n",
      "[I 2025-10-07 16:43:28,106] Trial 25 finished with value: 0.907608695652174 and parameters: {'iterations': 147, 'depth': 3, 'learning_rate': 0.04167227291677517}. Best is trial 22 with value: 0.9130434782608695.\n",
      "[I 2025-10-07 16:43:28,219] Trial 26 finished with value: 0.9021739130434783 and parameters: {'iterations': 199, 'depth': 5, 'learning_rate': 0.06403784492763503}. Best is trial 22 with value: 0.9130434782608695.\n",
      "[I 2025-10-07 16:43:28,303] Trial 27 finished with value: 0.8913043478260869 and parameters: {'iterations': 132, 'depth': 4, 'learning_rate': 0.07005272378963565}. Best is trial 22 with value: 0.9130434782608695.\n",
      "[I 2025-10-07 16:43:28,540] Trial 28 finished with value: 0.875 and parameters: {'iterations': 238, 'depth': 5, 'learning_rate': 0.14772418635063203}. Best is trial 22 with value: 0.9130434782608695.\n",
      "[I 2025-10-07 16:43:28,720] Trial 29 finished with value: 0.907608695652174 and parameters: {'iterations': 180, 'depth': 7, 'learning_rate': 0.05261171839407043}. Best is trial 22 with value: 0.9130434782608695.\n",
      "[I 2025-10-07 16:43:28,722] A new study created in memory with name: no-name-eab7ed80-af64-4627-a7ff-55467edd6d1a\n",
      "[I 2025-10-07 16:43:28,877] Trial 0 finished with value: 0.8804347826086957 and parameters: {'n_estimators': 261, 'max_depth': 9, 'learning_rate': 0.021554815556302814}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:28,920] Trial 1 finished with value: 0.8804347826086957 and parameters: {'n_estimators': 104, 'max_depth': 5, 'learning_rate': 0.03375589782905437}. Best is trial 0 with value: 0.8804347826086957.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CatBoost Accuracy: 0.9130434782608695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 16:43:29,048] Trial 2 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 244, 'max_depth': 8, 'learning_rate': 0.19754857536194362}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:29,166] Trial 3 finished with value: 0.8804347826086957 and parameters: {'n_estimators': 137, 'max_depth': 8, 'learning_rate': 0.15758649245576412}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:29,278] Trial 4 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 247, 'max_depth': 15, 'learning_rate': 0.276015129508446}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:29,331] Trial 5 finished with value: 0.8532608695652174 and parameters: {'n_estimators': 230, 'max_depth': 4, 'learning_rate': 0.2282487802759968}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:29,497] Trial 6 finished with value: 0.8478260869565217 and parameters: {'n_estimators': 337, 'max_depth': 9, 'learning_rate': 0.1301022306878854}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:29,652] Trial 7 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 272, 'max_depth': 14, 'learning_rate': 0.08872580394672673}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:29,737] Trial 8 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 145, 'max_depth': 13, 'learning_rate': 0.19002648917083423}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:29,786] Trial 9 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 286, 'max_depth': 3, 'learning_rate': 0.17768738424328734}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:30,066] Trial 10 finished with value: 0.875 and parameters: {'n_estimators': 455, 'max_depth': 11, 'learning_rate': 0.015333421152057242}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:30,211] Trial 11 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 384, 'max_depth': 6, 'learning_rate': 0.02101842379837804}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:30,261] Trial 12 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 111, 'max_depth': 6, 'learning_rate': 0.06801988477640121}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:30,374] Trial 13 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 201, 'max_depth': 11, 'learning_rate': 0.0652083626244738}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:30,451] Trial 14 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 181, 'max_depth': 6, 'learning_rate': 0.10729164986531116}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:30,593] Trial 15 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.045024221080790384}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:30,801] Trial 16 finished with value: 0.8804347826086957 and parameters: {'n_estimators': 365, 'max_depth': 10, 'learning_rate': 0.013914758687865954}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:30,860] Trial 17 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 101, 'max_depth': 8, 'learning_rate': 0.12273732692951933}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:30,969] Trial 18 finished with value: 0.875 and parameters: {'n_estimators': 180, 'max_depth': 12, 'learning_rate': 0.04853172777694724}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:31,026] Trial 19 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 325, 'max_depth': 3, 'learning_rate': 0.09304824459234491}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:31,155] Trial 20 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 428, 'max_depth': 7, 'learning_rate': 0.2995883272977058}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:31,236] Trial 21 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 144, 'max_depth': 9, 'learning_rate': 0.15124177814836282}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:31,300] Trial 22 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 136, 'max_depth': 7, 'learning_rate': 0.2383438126659967}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:31,418] Trial 23 finished with value: 0.8532608695652174 and parameters: {'n_estimators': 207, 'max_depth': 10, 'learning_rate': 0.15288937733060884}. Best is trial 0 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:43:31,478] Trial 24 finished with value: 0.8858695652173914 and parameters: {'n_estimators': 164, 'max_depth': 5, 'learning_rate': 0.04168233495367904}. Best is trial 24 with value: 0.8858695652173914.\n",
      "[I 2025-10-07 16:43:31,531] Trial 25 finished with value: 0.8804347826086957 and parameters: {'n_estimators': 177, 'max_depth': 4, 'learning_rate': 0.040649852983050835}. Best is trial 24 with value: 0.8858695652173914.\n",
      "[I 2025-10-07 16:43:31,588] Trial 26 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 162, 'max_depth': 5, 'learning_rate': 0.0739399603923326}. Best is trial 24 with value: 0.8858695652173914.\n",
      "[I 2025-10-07 16:43:31,627] Trial 27 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 111, 'max_depth': 4, 'learning_rate': 0.03904984243431743}. Best is trial 27 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 16:43:31,685] Trial 28 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 221, 'max_depth': 4, 'learning_rate': 0.05690536261837701}. Best is trial 27 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 16:43:31,744] Trial 29 finished with value: 0.8858695652173914 and parameters: {'n_estimators': 301, 'max_depth': 3, 'learning_rate': 0.035866615080592204}. Best is trial 27 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 16:43:31,746] A new study created in memory with name: no-name-e68c10f0-79dd-461f-98d4-924b11539303\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LightGBM Accuracy: 0.8913043478260869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 16:43:32,689] Trial 0 finished with value: 0.8478260869565217 and parameters: {'n_estimators': 468, 'max_depth': 12, 'learning_rate': 0.2493373538576053}. Best is trial 0 with value: 0.8478260869565217.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:33,507] Trial 1 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 223, 'max_depth': 14, 'learning_rate': 0.2673726367257819}. Best is trial 1 with value: 0.8641304347826086.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:34,128] Trial 2 finished with value: 0.8532608695652174 and parameters: {'n_estimators': 222, 'max_depth': 4, 'learning_rate': 0.1757828783421247}. Best is trial 1 with value: 0.8641304347826086.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:34,573] Trial 3 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 240, 'max_depth': 3, 'learning_rate': 0.24926325893599152}. Best is trial 1 with value: 0.8641304347826086.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:35,689] Trial 4 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 411, 'max_depth': 11, 'learning_rate': 0.13350988312402032}. Best is trial 1 with value: 0.8641304347826086.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:36,397] Trial 5 finished with value: 0.8478260869565217 and parameters: {'n_estimators': 339, 'max_depth': 9, 'learning_rate': 0.2897541453612782}. Best is trial 1 with value: 0.8641304347826086.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:37,617] Trial 6 finished with value: 0.842391304347826 and parameters: {'n_estimators': 395, 'max_depth': 9, 'learning_rate': 0.27953817106357}. Best is trial 1 with value: 0.8641304347826086.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:39,440] Trial 7 finished with value: 0.8369565217391305 and parameters: {'n_estimators': 484, 'max_depth': 14, 'learning_rate': 0.23081443867055237}. Best is trial 1 with value: 0.8641304347826086.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:40,507] Trial 8 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 284, 'max_depth': 8, 'learning_rate': 0.20549617210673823}. Best is trial 1 with value: 0.8641304347826086.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:41,984] Trial 9 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 320, 'max_depth': 9, 'learning_rate': 0.12770635910356462}. Best is trial 9 with value: 0.8695652173913043.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:42,304] Trial 10 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 108, 'max_depth': 7, 'learning_rate': 0.05150286697218702}. Best is trial 9 with value: 0.8695652173913043.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:43,244] Trial 11 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 157, 'max_depth': 14, 'learning_rate': 0.1027198886266131}. Best is trial 9 with value: 0.8695652173913043.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:44,430] Trial 12 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 320, 'max_depth': 6, 'learning_rate': 0.08545846740537709}. Best is trial 9 with value: 0.8695652173913043.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:45,579] Trial 13 finished with value: 0.875 and parameters: {'n_estimators': 213, 'max_depth': 11, 'learning_rate': 0.14474095460249836}. Best is trial 13 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:45] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:46,415] Trial 14 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 159, 'max_depth': 11, 'learning_rate': 0.16648575126245732}. Best is trial 13 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:48,048] Trial 15 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 286, 'max_depth': 11, 'learning_rate': 0.015719359051217546}. Best is trial 13 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:48,812] Trial 16 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 370, 'max_depth': 6, 'learning_rate': 0.12233799074965937}. Best is trial 13 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:49,654] Trial 17 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 257, 'max_depth': 12, 'learning_rate': 0.1919702316664157}. Best is trial 13 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:49] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:50,213] Trial 18 finished with value: 0.8586956521739131 and parameters: {'n_estimators': 178, 'max_depth': 10, 'learning_rate': 0.1431133785522687}. Best is trial 13 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:51,270] Trial 19 finished with value: 0.8532608695652174 and parameters: {'n_estimators': 341, 'max_depth': 8, 'learning_rate': 0.07065519530520277}. Best is trial 13 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:51,900] Trial 20 finished with value: 0.875 and parameters: {'n_estimators': 189, 'max_depth': 15, 'learning_rate': 0.11047339736584912}. Best is trial 13 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:52,672] Trial 21 finished with value: 0.875 and parameters: {'n_estimators': 193, 'max_depth': 15, 'learning_rate': 0.10845556403677818}. Best is trial 13 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:53,378] Trial 22 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 189, 'max_depth': 15, 'learning_rate': 0.1034225085127608}. Best is trial 13 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:53,904] Trial 23 finished with value: 0.842391304347826 and parameters: {'n_estimators': 140, 'max_depth': 15, 'learning_rate': 0.04193824229752119}. Best is trial 13 with value: 0.875.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:53] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:54,327] Trial 24 finished with value: 0.8804347826086957 and parameters: {'n_estimators': 102, 'max_depth': 13, 'learning_rate': 0.15849917229968644}. Best is trial 24 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:54] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:54,701] Trial 25 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 101, 'max_depth': 13, 'learning_rate': 0.15590453876817575}. Best is trial 24 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:54] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:57,463] Trial 26 finished with value: 0.8695652173913043 and parameters: {'n_estimators': 136, 'max_depth': 13, 'learning_rate': 0.20328620159601968}. Best is trial 24 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:58,090] Trial 27 finished with value: 0.8532608695652174 and parameters: {'n_estimators': 206, 'max_depth': 13, 'learning_rate': 0.1862139864886367}. Best is trial 24 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:43:59,691] Trial 28 finished with value: 0.8641304347826086 and parameters: {'n_estimators': 123, 'max_depth': 12, 'learning_rate': 0.14472384616000625}. Best is trial 24 with value: 0.8804347826086957.\n",
      "/home/ninakhay/miniforge3/envs/phase1-29.09/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [16:43:59] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-10-07 16:44:00,656] Trial 29 finished with value: 0.8532608695652174 and parameters: {'n_estimators': 266, 'max_depth': 13, 'learning_rate': 0.22141719262152282}. Best is trial 24 with value: 0.8804347826086957.\n",
      "[I 2025-10-07 16:44:00,657] A new study created in memory with name: no-name-f73413b3-ce0f-40f1-b41f-618ac8f150a0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Accuracy: 0.8804347826086957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-07 16:44:01,022] Trial 0 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 225, 'max_depth': 19, 'min_samples_split': 8}. Best is trial 0 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 16:44:01,236] Trial 1 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 146, 'max_depth': 6, 'min_samples_split': 7}. Best is trial 0 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 16:44:01,437] Trial 2 finished with value: 0.8858695652173914 and parameters: {'n_estimators': 122, 'max_depth': 14, 'min_samples_split': 4}. Best is trial 0 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 16:44:01,702] Trial 3 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 205, 'max_depth': 3, 'min_samples_split': 9}. Best is trial 0 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 16:44:01,824] Trial 4 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 77, 'max_depth': 10, 'min_samples_split': 8}. Best is trial 0 with value: 0.8913043478260869.\n",
      "[I 2025-10-07 16:44:02,065] Trial 5 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 163, 'max_depth': 6, 'min_samples_split': 7}. Best is trial 5 with value: 0.8967391304347826.\n",
      "[I 2025-10-07 16:44:02,361] Trial 6 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 211, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 5 with value: 0.8967391304347826.\n",
      "[I 2025-10-07 16:44:02,514] Trial 7 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 98, 'max_depth': 7, 'min_samples_split': 3}. Best is trial 5 with value: 0.8967391304347826.\n",
      "[I 2025-10-07 16:44:02,630] Trial 8 finished with value: 0.9021739130434783 and parameters: {'n_estimators': 69, 'max_depth': 16, 'min_samples_split': 10}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:02,997] Trial 9 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 276, 'max_depth': 4, 'min_samples_split': 8}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:03,106] Trial 10 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 59, 'max_depth': 18, 'min_samples_split': 10}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:03,358] Trial 11 finished with value: 0.8858695652173914 and parameters: {'n_estimators': 159, 'max_depth': 14, 'min_samples_split': 6}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:03,543] Trial 12 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 112, 'max_depth': 10, 'min_samples_split': 10}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:04,031] Trial 13 finished with value: 0.8858695652173914 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 2}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:04,319] Trial 14 finished with value: 0.8858695652173914 and parameters: {'n_estimators': 179, 'max_depth': 17, 'min_samples_split': 6}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:04,716] Trial 15 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 255, 'max_depth': 8, 'min_samples_split': 9}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:04,819] Trial 16 finished with value: 0.875 and parameters: {'n_estimators': 59, 'max_depth': 11, 'min_samples_split': 6}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:05,044] Trial 17 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 140, 'max_depth': 16, 'min_samples_split': 7}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:05,184] Trial 18 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 82, 'max_depth': 13, 'min_samples_split': 4}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:05,474] Trial 19 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 181, 'max_depth': 20, 'min_samples_split': 9}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:05,849] Trial 20 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 240, 'max_depth': 12, 'min_samples_split': 10}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:06,129] Trial 21 finished with value: 0.8967391304347826 and parameters: {'n_estimators': 193, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:06,464] Trial 22 finished with value: 0.8858695652173914 and parameters: {'n_estimators': 211, 'max_depth': 8, 'min_samples_split': 5}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:06,678] Trial 23 finished with value: 0.875 and parameters: {'n_estimators': 160, 'max_depth': 3, 'min_samples_split': 5}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:07,023] Trial 24 finished with value: 0.9021739130434783 and parameters: {'n_estimators': 231, 'max_depth': 6, 'min_samples_split': 7}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:07,437] Trial 25 finished with value: 0.9021739130434783 and parameters: {'n_estimators': 263, 'max_depth': 9, 'min_samples_split': 7}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:07,849] Trial 26 finished with value: 0.9021739130434783 and parameters: {'n_estimators': 264, 'max_depth': 9, 'min_samples_split': 7}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:08,309] Trial 27 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 297, 'max_depth': 11, 'min_samples_split': 8}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:08,670] Trial 28 finished with value: 0.9021739130434783 and parameters: {'n_estimators': 239, 'max_depth': 8, 'min_samples_split': 9}. Best is trial 8 with value: 0.9021739130434783.\n",
      "[I 2025-10-07 16:44:09,026] Trial 29 finished with value: 0.8913043478260869 and parameters: {'n_estimators': 229, 'max_depth': 19, 'min_samples_split': 8}. Best is trial 8 with value: 0.9021739130434783.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest Accuracy: 0.9021739130434783\n",
      "Все результаты: {'CatBoost': 0.9130434782608695, 'LightGBM': 0.8913043478260869, 'XGBoost': 0.8804347826086957, 'RandomForest': 0.9021739130434783}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "# Оптимизация для CatBoost\n",
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 500),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return accuracy_score(y_valid, preds)\n",
    "\n",
    "study_cat = optuna.create_study(direction='maximize')\n",
    "study_cat.optimize(objective_catboost, n_trials=30)\n",
    "results['CatBoost'] = study_cat.best_trial.value\n",
    "print(\"Best CatBoost Accuracy:\", study_cat.best_trial.value)\n",
    "\n",
    "# Оптимизация для LightGBM\n",
    "def objective_lgbm(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'random_state': 42,\n",
    "        'verbosity': -1,\n",
    "        'objective': 'binary'\n",
    "    }\n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return accuracy_score(y_valid, preds)\n",
    "\n",
    "study_lgbm = optuna.create_study(direction='maximize')\n",
    "study_lgbm.optimize(objective_lgbm, n_trials=30)\n",
    "results['LightGBM'] = study_lgbm.best_trial.value\n",
    "print(\"Best LightGBM Accuracy:\", study_lgbm.best_trial.value)\n",
    "\n",
    "# Оптимизация для XGBoost\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'random_state': 42,\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return accuracy_score(y_valid, preds)\n",
    "\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=30)\n",
    "results['XGBoost'] = study_xgb.best_trial.value\n",
    "print(\"Best XGBoost Accuracy:\", study_xgb.best_trial.value)\n",
    "\n",
    "# Оптимизация для RandomForest (чтобы было)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def objective_rf(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return accuracy_score(y_valid, preds)\n",
    "\n",
    "study_rf = optuna.create_study(direction='maximize')\n",
    "study_rf.optimize(objective_rf, n_trials=30)\n",
    "results['RandomForest'] = study_rf.best_trial.value\n",
    "print(\"Best RandomForest Accuracy:\", study_rf.best_trial.value)\n",
    "\n",
    "print(\"Все результаты:\", results)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbb5cfb9-033f-4318-8280-199cdeb6c239",
   "metadata": {},
   "source": [
    "4. Превращаем словарь в `DataFrame` и сравниваем полученные результаты. Строим `bar_plot` для визуализации метрики качества. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a16845f8-619a-4111-b4b3-c2e8abefdc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = {'CatBoost': 0.9130434782608695, \n",
    "           'LightGBM': 0.8913043478260869, \n",
    "           'XGBoost': 0.8804347826086957, \n",
    "           'RandomForest': 0.9021739130434783}\n",
    "\n",
    "df_results = pd.DataFrame(list(results.items()), columns=['Model', 'Accuracy'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(df_results['Model'], df_results['Accuracy'], color='skyblue')\n",
    "plt.title('Сравнение Accuracy моделей')\n",
    "plt.xlabel('Модель')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(df_results['Accuracy']):\n",
    "    plt.text(i, v + 0.01, f\"{v:.3f}\", ha='center', fontsize=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Выберете лучшую модель и попробуйте задеплоить ее в Streamlit.\n",
    "\n",
    "* Создайте просто интерфейс для пользователя, куда бы он мог ввести необходимые данные, а вы бы ему вернули предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d1dfc62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0c8928ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoders.pkl']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import streamlit as st\n",
    "\n",
    "catboost_model = CatBoostClassifier(random_seed=42, verbose=0)\n",
    "catboost_model.fit(X_train, y_train)\n",
    "joblib.dump(catboost_model, 'catboost_model.pkl')\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
    "joblib.dump(label_encoders, 'label_encoders.pkl')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phase1-29.09",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
