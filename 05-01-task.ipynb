{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "714c8d03-3e1e-4f9b-8905-13d24d8b06da",
   "metadata": {},
   "source": [
    "## Неделя 2. Понедельник\n",
    "### Обучение с учителем"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0625aa32-3502-431d-8f0f-4e81ba1d9424",
   "metadata": {},
   "source": [
    "### Применение базовых методов классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0cd521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a52b4c",
   "metadata": {},
   "source": [
    "#### 0. Ознакомьтесь с датасетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddd6feb5-6323-4610-855e-2b6797c693cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>45.0</td>\n",
       "      <td>M</td>\n",
       "      <td>TA</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>132</td>\n",
       "      <td>N</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>68.0</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>141</td>\n",
       "      <td>N</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>57.0</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>115</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>57.0</td>\n",
       "      <td>F</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>LVH</td>\n",
       "      <td>174</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>38.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>173</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  \\\n",
       "0    40.0   M           ATA        140          289          0     Normal   \n",
       "1    49.0   F           NAP        160          180          0     Normal   \n",
       "2    37.0   M           ATA        130          283          0         ST   \n",
       "3    48.0   F           ASY        138          214          0     Normal   \n",
       "4    54.0   M           NAP        150          195          0     Normal   \n",
       "..    ...  ..           ...        ...          ...        ...        ...   \n",
       "913  45.0   M            TA        110          264          0     Normal   \n",
       "914  68.0   M           ASY        144          193          1     Normal   \n",
       "915  57.0   M           ASY        130          131          0     Normal   \n",
       "916  57.0   F           ATA        130          236          0        LVH   \n",
       "917  38.0   M           NAP        138          175          0     Normal   \n",
       "\n",
       "     MaxHR ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0      172              N      0.0       Up             0  \n",
       "1      156              N      1.0     Flat             1  \n",
       "2       98              N      0.0       Up             0  \n",
       "3      108              Y      1.5     Flat             1  \n",
       "4      122              N      0.0       Up             0  \n",
       "..     ...            ...      ...      ...           ...  \n",
       "913    132              N      1.2     Flat             1  \n",
       "914    141              N      3.4     Flat             1  \n",
       "915    115              Y      1.2     Flat             1  \n",
       "916    174              N      0.0     Flat             1  \n",
       "917    173              N      0.0       Up             0  \n",
       "\n",
       "[918 rows x 12 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('heart.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b4eb3",
   "metadata": {},
   "source": [
    "* __Age__: age of the patient [years]\n",
    "* __Sex__: sex of the patient [M: Male, F: Female]\n",
    "* __ChestPainType__: chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]\n",
    "* __RestingBP__: resting blood pressure [mm Hg]\n",
    "* __Cholesterol__: serum cholesterol [mm/dl]\n",
    "* __FastingBS__: fasting blood sugar [1: if FastingBS > 120 mg/dl, 0: otherwise]\n",
    "* __RestingECG__: resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite * left ventricular hypertrophy by Estes' criteria]\n",
    "* __MaxHR__: maximum heart rate achieved [Numeric value between 60 and 202]\n",
    "* __ExerciseAngina__: exercise-induced angina [Y: Yes, N: No]\n",
    "* __Oldpeak__: oldpeak = ST [Numeric value measured in depression]\n",
    "* __ST_Slope__: the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]\n",
    "* __HeartDisease__: output class [1: heart disease, 0: Normal]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697991a7",
   "metadata": {},
   "source": [
    "* Таргетом является столбец `HeartDisease`. Необходимо предсказать по имеющимся данным, есть ли проблемы с сердцем"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8402d8-13bd-4ecf-ae56-164ab50e7f01",
   "metadata": {},
   "source": [
    "#### 1. Небольшие рекомендации ниже "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fdc8a1",
   "metadata": {},
   "source": [
    "\n",
    "* __Baseline pipeline (базовый пайплайн)__ - это простой пайплайн, который используется как отправная точка или точка сравнения при разработке и оценке более сложных моделей или алгоритмов. \n",
    "\n",
    "* Для этого сначала используйте самые простые идеи по заполнению пропусков(средними, медианами, модами) и кодированию категориальных данных, которые вам приходят в голову. \n",
    "\n",
    "* После того, как вы построите модели провалидируете их. Можно будет приступать к попыткам улучшить свою модель с помощью ваших идей - пробовать создавать новые фичи, кодировать данные по-другому, заполнять иначе NaN и тд"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8420c83-43fa-4ee1-95cf-5d43e8058a49",
   "metadata": {},
   "source": [
    "#### 2. Заполните пропущенные значения(`Imputing`), как считаете нужным.  \n",
    "\n",
    "- Не забывайте памятку выше, сначала заполняйте самыми тривиальными идеями. Наприсер, средними, медианами и т.д"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0298a9eb-9a82-4d42-b4ec-b7d037204aee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               10\n",
       "Sex                0\n",
       "ChestPainType      0\n",
       "RestingBP          0\n",
       "Cholesterol        0\n",
       "FastingBS          0\n",
       "RestingECG         0\n",
       "MaxHR              0\n",
       "ExerciseAngina     0\n",
       "Oldpeak            0\n",
       "ST_Slope           0\n",
       "HeartDisease       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25f24e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               0\n",
       "Sex               0\n",
       "ChestPainType     0\n",
       "RestingBP         0\n",
       "Cholesterol       0\n",
       "FastingBS         0\n",
       "RestingECG        0\n",
       "MaxHR             0\n",
       "ExerciseAngina    0\n",
       "Oldpeak           0\n",
       "ST_Slope          0\n",
       "HeartDisease      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f78af",
   "metadata": {},
   "source": [
    "##### 2.1 Оберните в `ColumnTransformer` свой `Imputing` данных. Проверьте корректность его работы. Для этого необходимо сделать:\n",
    "\n",
    "1. Обучить и трансформировать свой `Imputer` с помощью `your_imputer.fit_transform` - на тренировочных данных\n",
    "2. Заполнить с помощью `your_imputer.transform` - на тестовых данных\n",
    "\n",
    "Убедитесь, что данные прошли через этап `Imputing'а` и пропусков в них больше нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "029fc94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532160b",
   "metadata": {},
   "source": [
    "ColumnTransformer` свой `Imputing` данных. Проверьте корректность его работы. Для этого необходимо сделать:\n",
    "\n",
    "1. Обучить и трансформировать свой `Imputer` с помощью `your_imputer.fit_transform` - на тренировочных данных\n",
    "2. Заполнить с помощью `your_imputer.transform` - на тестовых данных\n",
    "\n",
    "Убедитесь, что данные прошли через этап `Imputing'а` и пропусков в них больше нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d65c796f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропуски в X_train_imputed:\n",
      " Age               0\n",
      "RestingBP         0\n",
      "Cholesterol       0\n",
      "FastingBS         0\n",
      "MaxHR             0\n",
      "Oldpeak           0\n",
      "Sex               0\n",
      "ChestPainType     0\n",
      "RestingECG        0\n",
      "ExerciseAngina    0\n",
      "ST_Slope          0\n",
      "dtype: int64\n",
      "Пропуски в X_valid_imputed:\n",
      " Age               0\n",
      "RestingBP         0\n",
      "Cholesterol       0\n",
      "FastingBS         0\n",
      "MaxHR             0\n",
      "Oldpeak           0\n",
      "Sex               0\n",
      "ChestPainType     0\n",
      "RestingECG        0\n",
      "ExerciseAngina    0\n",
      "ST_Slope          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('HeartDisease', axis=1) # без таргета\n",
    "y = df['HeartDisease'] # таргет\n",
    "\n",
    "# делим на с таргетом и без\n",
    "X, y = df.drop('HeartDisease', axis=1), df['HeartDisease']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "num_features = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak']\n",
    "cat_features = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='mean')           # заполнение средним для числовых\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')  # заполнение модой для категориальных\n",
    "\n",
    "my_imputer = ColumnTransformer(\n",
    "    transformers = [('num', num_imputer, num_features), ('cat', cat_imputer, cat_features)])\n",
    "\n",
    "X_train_imputed = my_imputer.fit_transform(X_train) # обучение и применение на train\n",
    "X_valid_imputed = my_imputer.transform(X_valid) # только применение на valid\n",
    "\n",
    "# X_train — обучающие признаки (80% от X)\n",
    "# X_valid — валидационные признаки (20% от X)\n",
    "# y_train — целевая переменная для обучения\n",
    "# y_valid — целевая переменная для валидации\n",
    "# X — признаки (features) все кроме 'HeartDisease'\n",
    "# y — целевая переменная (target) df['HeartDisease']\n",
    "\n",
    "# проверяем что пропусков нет\n",
    "# преобразуем обратно в DataFrame, чтобы удобно проверить пропуски\n",
    "X_train_imputed_df = pd.DataFrame(X_train_imputed, columns=num_features + cat_features)\n",
    "X_valid_imputed_df = pd.DataFrame(X_valid_imputed, columns=num_features + cat_features)\n",
    "\n",
    "print(\"Пропуски в X_train_imputed:\\n\", X_train_imputed_df.isnull().sum())\n",
    "print(\"Пропуски в X_valid_imputed:\\n\", X_valid_imputed_df.isnull().sum())\n",
    "\n",
    "\n",
    "# сохранить новывй датафрейм предобработанный\n",
    "# преобразуем массивы обратно в DataFrame с именами колонок и индексами для сохранения порядка\n",
    "X_train_imputed_df = pd.DataFrame(X_train_imputed, columns=num_features + cat_features, index=X_train.index)\n",
    "X_valid_imputed_df = pd.DataFrame(X_valid_imputed, columns=num_features + cat_features, index=X_valid.index)\n",
    "\n",
    "# добавим целевую переменную (таргет) обратно в датафреймы\n",
    "X_train_imputed_df['HeartDisease'] = y_train\n",
    "X_valid_imputed_df['HeartDisease'] = y_valid\n",
    "\n",
    "# Сохраняем в csv без индекса, чтобы было чисто\n",
    "# X_train_imputed_df.to_csv('aux/X_train_imputed.csv', index=False)\n",
    "# X_valid_imputed_df.to_csv('aux/X_valid_imputed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c20430e-ba3d-4759-9307-339d7cf76c4c",
   "metadata": {},
   "source": [
    "#### 3. Закодируйте категориальные переменные, как считаете нужным"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fbe584",
   "metadata": {},
   "source": [
    "* `OneHotEncoding` (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)  \n",
    "* `TargetEncoding` (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.TargetEncoder.html)  \n",
    "* `OrdinalEncoding` (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html)  \n",
    "* `CatBoostEncoding` (https://www.geeksforgeeks.org/categorical-encoding-with-catboost-encoder/)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16463e89-ba9e-43c1-96d4-d8c78c8c1914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler, MinMaxScaler, OrdinalEncoder, TargetEncoder\n",
    "\n",
    "ordinal_encoding_columns = ['Sex'] # Столбец, который планируем кодировать порядково, с помощью OrdinalEncoder \n",
    "one_hot_encoding_columns = ['ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope'] # Столбец, который планируем кодировать с помощью OneHotEncoder \n",
    "standard_scaler_columns = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak'] # Числовые столбцы, которые необходимо пронормировать\n",
    "\n",
    "\n",
    "scaler_and_encoder = ColumnTransformer(\n",
    "    [\n",
    "        ('ordinal_encoding', OrdinalEncoder(), ordinal_encoding_columns),\n",
    "        ('one_hot_encoding_columns', OneHotEncoder(sparse_output=False), one_hot_encoding_columns),\n",
    "        ('scaling_num_columns', StandardScaler(), standard_scaler_columns)\n",
    "    ],\n",
    "    verbose_feature_names_out = False,\n",
    "    remainder = 'passthrough' \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb10055",
   "metadata": {},
   "source": [
    "##### 3.1 Оберните в `ColumnTransformer` свой `Encoding` данных. Проверьте корректность его работы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43db5942",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма X_train_encoded: (734, 13)\n",
      "Форма X_valid_encoded: (184, 13)\n"
     ]
    }
   ],
   "source": [
    "# тут отдельно категориальные признаки кодируем\n",
    "\n",
    "ordinal_encoding_columns = ['Sex']\n",
    "one_hot_encoding_columns = ['ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "\n",
    "my_encoder = ColumnTransformer([\n",
    "    ('ordinal_encoding', OrdinalEncoder(), ordinal_encoding_columns),\n",
    "    ('one_hot_encoding', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), one_hot_encoding_columns)\n",
    "], verbose_feature_names_out=False)\n",
    "\n",
    "# кодируем тренировочные данные после импьютинга\n",
    "X_train_encoded = my_encoder.fit_transform(X_train_imputed_df)\n",
    "\n",
    "# кодируем валидационные данные\n",
    "X_valid_encoded = my_encoder.transform(X_valid_imputed_df)\n",
    "\n",
    "print(\"Форма X_train_encoded:\", X_train_encoded.shape)\n",
    "print(\"Форма X_valid_encoded:\", X_valid_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4c9367",
   "metadata": {},
   "source": [
    "#### 4. То же самое проделать с нормализацией данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505dc27d",
   "metadata": {},
   "source": [
    "* `StandardScaler` (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "* `MinMaxScaler` (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
    "* `RobustScaler` (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3249b0",
   "metadata": {},
   "source": [
    "#### 4.1 Оберните в `ColumnTransformer` свой `Scaling` данных, проверьте корректность работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50fdab1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма X_train_scaled: (734, 6)\n",
      "Форма X_valid_scaled: (184, 6)\n"
     ]
    }
   ],
   "source": [
    "# тут отдельно числовые признаки кодируем\n",
    "standard_scaler_columns = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak']\n",
    "\n",
    "my_scaler = ColumnTransformer([\n",
    "    ('scaling_num_columns', StandardScaler(), standard_scaler_columns)\n",
    "], verbose_feature_names_out=False)\n",
    "\n",
    "# Применяем масштабирование к числовым признакам\n",
    "X_train_scaled = my_scaler.fit_transform(X_train_imputed_df)\n",
    "X_valid_scaled = my_scaler.transform(X_valid_imputed_df)\n",
    "\n",
    "print(\"Форма X_train_scaled:\", X_train_scaled.shape)\n",
    "print(\"Форма X_valid_scaled:\", X_valid_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696faaab",
   "metadata": {},
   "source": [
    "#### 5. Соберите весь препроцессинг в общий Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5a4464e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# выделим типы признаков\n",
    "num_features = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak']\n",
    "cat_ordinal_features = ['Sex']\n",
    "cat_onehot_features = ['ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "\n",
    "# отдельные пайплайны для каждого типа признаков\n",
    "\n",
    "# числовой пайплайн: Импутинг + масштабирование\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# категориальный пайплайн: Импутинг + OrdinalEncoder\n",
    "cat_ordinal_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "# категориальный пайплайн: Импутинг + OneHotEncoder\n",
    "cat_onehot_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# общий ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat_ord', cat_ordinal_pipeline, cat_ordinal_features),\n",
    "    ('cat_onehot', cat_onehot_pipeline, cat_onehot_features)\n",
    "], verbose_feature_names_out=False)\n",
    "\n",
    "preprocessor = Pipeline([\n",
    "    ('preprocessing', preprocessor)  # наш ColumnTransformer, собранный выше\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c7265",
   "metadata": {},
   "source": [
    "##### 5.1 Прогоните свои данные через `preprocessor` и убедитесь, что ваши данные проходят через него корректно и уже готовы к ML-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "789f41e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма X_train_processed: (734, 19)\n",
      "Форма X_valid_processed: (184, 19)\n",
      "Пропуски в X_train_processed: 0\n",
      "Пропуски в X_valid_processed: 0\n"
     ]
    }
   ],
   "source": [
    "# Обучаем preprocessor на тренировочных данных (fit + transform)\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Применяем обученный preprocessor к валидационным данным (только transform)\n",
    "X_valid_processed = preprocessor.transform(X_valid)\n",
    "\n",
    "# Проверяем форму результата (кол-во объектов и признаков)\n",
    "print(\"Форма X_train_processed:\", X_train_processed.shape)\n",
    "print(\"Форма X_valid_processed:\", X_valid_processed.shape)\n",
    "\n",
    "# Проверяем, есть ли пропуски (NaN) после обработки\n",
    "\n",
    "print(\"Пропуски в X_train_processed:\", np.isnan(X_train_processed).sum())\n",
    "print(\"Пропуски в X_valid_processed:\", np.isnan(X_valid_processed).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1092ba61-e544-4f66-9050-8ceeb91905d5",
   "metadata": {},
   "source": [
    "#### 6.ML-модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe669a",
   "metadata": {},
   "source": [
    "* `LogisticRegression` (из `sklearn.linear_model`)  \n",
    "* `LogisticRegression with regularization` (из `sklearn.linear_model`)  \n",
    "* `KNeighborsClassifier` (из `sklearn.neighbors`)  \n",
    "* `DecisionTree` (из `sklearn.tree`)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f3069",
   "metadata": {},
   "source": [
    "##### 6.1 Обучите свой `Pipeline` с помощью метода `.fit()` с разными моделями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36b17c64-c706-43a4-a682-b4f8987f18ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение модели: LogisticRegression\n",
      "Accuracy модели LogisticRegression: 0.8859\n",
      "\n",
      "Обучение модели: LogisticRegression_with_regularization\n",
      "Accuracy модели LogisticRegression_with_regularization: 0.8859\n",
      "\n",
      "Обучение модели: KNeighborsClassifier\n",
      "Accuracy модели KNeighborsClassifier: 0.8804\n",
      "\n",
      "Обучение модели: DecisionTree\n",
      "Accuracy модели DecisionTree: 0.7717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# preprocessor - готовый ColumnTransformer\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=42),\n",
    "    \"LogisticRegression_with_regularization\": LogisticRegression(penalty='l2', C=1.0, solver='lbfgs', random_state=42),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Обучение модели: {model_name}\")\n",
    "    ml_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor), \n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # обучаем модель\n",
    "    ml_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # оцениваем точность на валидационных данных\n",
    "    score = ml_pipeline.score(X_valid, y_valid)\n",
    "    print(f\"Accuracy модели {model_name}: {score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4667f267-f3e2-424d-9a2f-2086955cac9e",
   "metadata": {},
   "source": [
    "#### 7. С помощью метода `.predict()` (на вход поступают только матрица признаков, без целевой переменной) предсказать значения на обучающей выборке (`X_train`) и валидационной выборке (`X_valid`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68b5a00e-2401-46ac-b1b3-ef05beddbf0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказания на тренировочных данных: [1 0 1 1 1 0 1 0 0 0]\n",
      "Предсказания на валидационных данных: [1 1 1 0 1 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# model_train_predict\n",
    "# model_valid_predict\n",
    "\n",
    "# предсказания на тренировочных данных\n",
    "model_train_predict = ml_pipeline.predict(X_train)\n",
    "\n",
    "# предсказания на валидационных данных\n",
    "model_valid_predict = ml_pipeline.predict(X_valid)\n",
    "\n",
    "print(\"Предсказания на тренировочных данных:\", model_train_predict[:10])\n",
    "print(\"Предсказания на валидационных данных:\", model_valid_predict[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc2e69f",
   "metadata": {},
   "source": [
    "##### 7.1 С помощью функции оценки качества (`accuracy_score`) собрать следующую таблицу ниже"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f034c64-fd18-401f-8510-d70fbaec4567",
   "metadata": {},
   "source": [
    "* значение функции на обучающих данных\n",
    "* значение функции на валидационных данных \n",
    "    \n",
    "Результатом выполнения этого пункта будет `DataFrame` формата: \n",
    "    \n",
    "|  |train|valid|\n",
    "|--|-----|-----|\n",
    "|**LogReg**|  train_score  | valid_score    |\n",
    "|**LogReg with l1**|  train_score  | valid_score    |\n",
    "|**LogReg with l2**|  train_score  | valid_score    |\n",
    "|**KNN**| train_score  |  valid_score   |\n",
    "|**Tree**| train_score | valid_score    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31fe7d74-51f3-4eee-aeb1-30510e5d2931",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.858311</td>\n",
       "      <td>0.885870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg with l1</th>\n",
       "      <td>0.863760</td>\n",
       "      <td>0.885870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg with l2</th>\n",
       "      <td>0.858311</td>\n",
       "      <td>0.885870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.870572</td>\n",
       "      <td>0.880435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tree</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.771739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   train     valid\n",
       "model                             \n",
       "LogReg          0.858311  0.885870\n",
       "LogReg with l1  0.863760  0.885870\n",
       "LogReg with l2  0.858311  0.885870\n",
       "KNN             0.870572  0.880435\n",
       "Tree            1.000000  0.771739"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# словарь моделей\n",
    "models = {\n",
    "    \"LogReg\": LogisticRegression(random_state=42),\n",
    "    \"LogReg with l1\": LogisticRegression(penalty='l1', solver='liblinear', random_state=42),\n",
    "    \"LogReg with l2\": LogisticRegression(penalty='l2', solver='lbfgs', random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Tree\": DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # создаем pipeline с препроцессингом и моделью\n",
    "    ml_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    # обучаем\n",
    "    ml_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # предсказания\n",
    "    train_pred = ml_pipeline.predict(X_train)\n",
    "    valid_pred = ml_pipeline.predict(X_valid)\n",
    "    \n",
    "    # считаем accuracy\n",
    "    train_acc = accuracy_score(y_train, train_pred)\n",
    "    valid_acc = accuracy_score(y_valid, valid_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'model': model_name,\n",
    "        'train': train_acc,\n",
    "        'valid': valid_acc\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).set_index('model')\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea107a10-358b-456f-9f0d-542ff1b8c98d",
   "metadata": {},
   "source": [
    "#### 8. Теперь реализуйте __кросс-валидацию__ с KFold=5 и выведите средний __score__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce272598-762e-4a79-8604-b89f5c060f56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cross_val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.856165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg with l1</th>\n",
       "      <td>0.858345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg with l2</th>\n",
       "      <td>0.856165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.862693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.863798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tree</th>\n",
       "      <td>0.789736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cross_val_score\n",
       "LogReg                 0.856165\n",
       "LogReg with l1         0.858345\n",
       "LogReg with l2         0.856165\n",
       "KNN                    0.862693\n",
       "SVC                    0.863798\n",
       "Tree                   0.789736"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "models = {\n",
    "    \"LogReg\": LogisticRegression(random_state=42),\n",
    "    \"LogReg with l1\": LogisticRegression(penalty='l1', solver='liblinear', random_state=42),\n",
    "    \"LogReg with l2\": LogisticRegression(penalty='l2', solver='lbfgs', random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVC\": SVC(random_state=42),\n",
    "    \"Tree\": DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    scores = cross_val_score(pipeline, X, y, cv=kf, scoring='accuracy')\n",
    "    results[name] = scores.mean()\n",
    "\n",
    "df_results = pd.DataFrame.from_dict(results, orient='index', columns=['cross_val_score'])\n",
    "df_results\n",
    "\n",
    "# логистическая регрессия работает лучше для этого датасета\n",
    "\n",
    "# train_test_split — разделение данных.\n",
    "# SimpleImputer — заполнение пропусков.\n",
    "# ColumnTransformer — применяет разные трансформации к разным колонкам.\n",
    "# OrdinalEncoder, OneHotEncoder — кодирование категориальных данных.\n",
    "# StandardScaler — масштабирование числовых признаков.\n",
    "# Pipeline — объединение шагов препроцессинга и модели.\n",
    "# LogisticRegression, KNeighborsClassifier, DecisionTreeClassifier, SVC — модели машинного обучения.\n",
    "# cross_val_score и KFold — кросс-валидация.\n",
    "# accuracy_score — метрика качества."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c56304-7af2-4698-be88-221ca97ef07b",
   "metadata": {},
   "source": [
    "|  |cross_val_score|\n",
    "|--|-----|\n",
    "|**LogReg**|  your_score |\n",
    "|**LogReg with l1**|  your_score  |\n",
    "|**LogReg with l2**|  your_score  |\n",
    "|**KNN**| your_score  |\n",
    "|**SVC**| your_score  |\n",
    "|**Tree**| your_score |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8340721-48eb-44d6-9944-115ece14cacb",
   "metadata": {},
   "source": [
    "<img src=\"https://icons.iconarchive.com/icons/icons8/windows-8/256/Programming-Github-icon.png\" width=32 /> Пора сохранить изменения для __github__. \n",
    "\n",
    "1. Перейди в командной строке в папку, в которой расположен этот нотбук. \n",
    "2. Выполни команду `git add 06-01-task.ipynb`\n",
    "3. Выполни команду `git commit -m \"base models in progress\"`\n",
    "4. Выполни команду `git push`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f45ec84-c286-4998-a611-cc287c29994b",
   "metadata": {},
   "source": [
    "##### 9. Теперь, когда вы проделали весь pipeline и обучили базовую модель, можно вернуться к началу и пробовать новые идеи и искать точки роста для ваших моделей, в том числе и добавление новых фичей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1dd31c-0b83-4e5e-9bd7-a167f3036545",
   "metadata": {},
   "source": [
    "<img src=\"https://icons.iconarchive.com/icons/icons8/windows-8/256/Programming-Github-icon.png\" width=32 /> Сохрани файл для __github__ и выполни команду `!git status` в ячейке ниже.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8b9da17-88db-439c-938c-199faa6dc3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# code\n",
    "# люди старше 60 сахар высокий True False\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7de5e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phase1-29.09",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
